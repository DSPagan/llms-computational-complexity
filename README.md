# Estimating Computational Complexity with Large Language Models

This repository contains the code, experiments, and documentation for my undergraduate thesis titled:

**"Estimating Computational Complexity with Large Language Models"**

## ðŸ§  Overview

The goal of this project is to investigate the potential of large language models (LLMs) to estimate the computational complexity of algorithms **without executing them**. Traditionally, this estimation requires either empirical testing with inputs of varying size or manual step-counting. Here, we explore a novel approach based on deep learning and natural language processing.

This research aims to support software developers in writing more efficient code by enabling LLMs to infer time or space complexity directly from algorithm descriptions or source code.

## ðŸ“‚ Structure

```bash
.
â”œâ”€â”€ src/                 # Source code for training and evaluation
â”œâ”€â”€ notebooks/           # Jupyter notebooks for exploration and visualization
â”œâ”€â”€ data/                # Datasets used for fine-tuning or evaluation
â”œâ”€â”€ memoria/             # Thesis document (PDF or LaTeX files)
â”œâ”€â”€ figures/             # Diagrams, charts, and illustrative materials
â””â”€â”€ README.md            # This file
